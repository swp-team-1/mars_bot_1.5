{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#static-view","title":"Static view","text":"<p>Cohesion</p> <ul> <li> <p>Telegram Bot is responsible only for receiving and sending messages to the user.</p> </li> <li> <p>Middleware handles the processing and routing of requests between components.</p> </li> <li> <p>The Database Connector implements all the logic of accessing the database.</p> </li> <li> <p>LLM is solely responsible for generating responses based on the received data.</p> </li> <li> <p>The database stores all the necessary information and query history.</p> </li> </ul> <p>Coupling</p> <ul> <li> <p>Telegram Bot does not interact directly with either the LLM or the database \u2014 it only works with Middleware.</p> </li> <li> <p>Middleware acts as the central link, receiving requests from the bot, accessing the database through the Database Connector and interacting with the LLM to receive a response.</p> </li> </ul> <p>Maintainability of our product</p> <p>1) Using a separate connector for working with the database and weak component interdependence (low coupling) make it easy to update or replace the database without significant changes to the rest of the system.</p> <p>2) The Telegram Bot component can be removed, and the same business logic can be embedded directly into the customer's existing application without significant rework.</p>"},{"location":"architecture/#deployment-view","title":"Deployment view","text":"<p>Our server system is deployed on the Railway server.</p> <p>To simplify integration with the customer's application, we provide documented API endpoints. The client can connect directly to these endpoints from their own application, making it easier to implement our server functions without having to change the existing interface or infrastructure.</p> <p>Deployment Highlights:</p> <p>Server: Railway (cloud server)</p> <p>Integration: The customer is provided with secure API endpoints to connect his application to our server.</p>"},{"location":"architecture/#dynamic-view","title":"Dynamic view","text":"<p>Average system response time based on test results in a production environment:</p> <ul> <li> <p>The bot's response: less than 1 second.</p> </li> <li> <p>LLM's answer: about 3 seconds on average.</p> </li> </ul>"},{"location":"deployment/","title":"Build and deployment","text":""},{"location":"deployment/#railway-deployment-instructions","title":"Railway deployment instructions","text":"<p>The Railway service is used to deploy our project. To repeat the project deployment, you can follow these steps:</p> <ol> <li> <p>Register or log in to your Railway account</p> </li> <li> <p>Click to button to deploy new project</p> </li> </ol> <p></p> <ol> <li>And choose project to deploy from the Github</li> </ol> <p></p> <ol> <li>Add enviroment variables:</li> </ol> <p></p> <ul> <li>4.1 Set your bot token</li> <li>4.2 Set webhook URL. You can find it in Settings -&gt; Networking section</li> </ul> <p></p> <ol> <li>Deploy project and make adjustments according to the logs </li> </ol>"},{"location":"deployment/#manual-deployment","title":"\ud83d\udce6 Manual deployment","text":"<ol> <li> <p>Clone the repo:    <code>bash    git clone https://github.com/swp-team-1/mars_bot_1.5.git    cd mars_bot_1.5</code></p> </li> <li> <p>Create and activate a virtual environment:    <code>bash    python3 -m venv venv    source venv/bin/activate  # On Windows: venv\\Scripts\\activate</code></p> </li> <li> <p>Install the requirements:    <code>bash    pip install -r requirements.txt</code></p> </li> <li> <p>Create an <code>.env</code> file (copy from <code>.env.example</code>) and configure:    <code>env    BOT_TOKEN=your_telegram_bot_token    MONGODB_URI=your_mongodb_connection_uri</code></p> </li> <li> <p>Run services:    <code>bash    uvicorn main:app --reload      # FastAPI backend    python bot_main.py             # Telegram bot</code></p> </li> </ol>"},{"location":"deployment/#continuous-integration","title":"Continuous Integration","text":"<p>Our project uses two separate CI pipelines: one for the database connector and one for the bot.</p>"},{"location":"deployment/#database-connector-ci","title":"Database connector CI","text":"<ul> <li> <p>CI Workflow: <code>.github/workflows/test.yml</code></p> </li> <li> <p>Static Analysis and Testing Tools Used:</p> </li> <li>pytest: Runs automated tests to verify code correctness.</li> <li>flake8: Ensures code style consistency and catches simple errors.</li> <li> <p>bandit: Scans the codebase for security vulnerabilities.</p> </li> <li> <p>Where to See CI Workflow Runs:   You can view all connector CI workflow runs for this project here: GitHub Actions Runs</p> </li> </ul>"},{"location":"deployment/#bot-ci","title":"Bot CI","text":"<ul> <li> <p>CI Workflow: <code>bot_aio/.github/workflows/test.yml</code></p> </li> <li> <p>Static Analysis and Testing Tools Used:</p> </li> <li>flake8: Ensures code style consistency and catches both critical and stylistic errors.</li> <li>mypy: Checks for type errors and enforces type safety.</li> <li> <p>pytest: Runs automated tests to verify code correctness.</p> </li> <li> <p>Where to See CI Workflow Runs:   You can view all bot CI workflow runs for this project here: GitHub Actions Runs</p> </li> </ul>"},{"location":"development/","title":"Development","text":"<p>Link to the Kanban board or this link, if you have account in Miro </p>"},{"location":"development/#entry-criteria","title":"Entry criteria","text":"TO DO In progress In review Ready to deploy User testing DONE - Discussion problem with team members- Prioritize among issues- A performer has been appointed- A branch has been created in the repository - Prioritize among issues- Issues are estimated- MR has been created - Code fully implemented and self-reviewed- Pass all tests- Branch rebased on main- min 2 reviewers assigned - MR is approved- The documentation is updated- All tasks for this issue are closed - Test Environment Ready- Customer is informed - Deployment is done- Documentation is done- Testing is complete"},{"location":"development/#git-workflow","title":"Git workflow","text":"<p>All project code you can find in our Github, however the main backlog is on our Gitlab repository. Our team has several rules of operation:</p>"},{"location":"development/#creating-issues-from-the-defined-templates","title":"Creating issues from the defined templates","text":"<ul> <li>We use the templates when creating</li> <li>Try to fill in all the fields in detail and correctly</li> </ul> <p>Labelling issues  - Mark tasks with a label based on the size of the task (S, M, L)  - Use a label to mark the urgency level of a task and its priority (high, medium, low)  - Use type labels such as \"Task\", \"Bug\" etc</p> <p>Assigning issues to team members  - Distribute the load evenly (no more than 2-3 L-tasks per person for a sprint)  - Assign tasks based on a person's specialization  - The assigned executor is responsible for progress and timely status updates.</p> <p>Creating, naming, merging branches  - When creating a branch, name it according to its purpose  - Make sure that name does not match the name of any existing (git branch --list)  - Merge the branch only after you've tested the code and made sure it works</p> <p>Commit messages format  - Briefly and clearly describe two things: which file/directory has changed, and what changes have occurred.</p>"},{"location":"development/#gitgraph-diagram","title":"Gitgraph diagram","text":"<p>Code reviews ( Pay attention to: )  - Code clarity  - Code style_  - Tests _(new code should include unit/integration tests, if applicable)  - Documentation</p> <p>Merging pull requests  - Minimum 2 approves  - All tests pass (CI/CD pipeline must be successful)  - Before merging, you must make sure that there are no conflicts with the main branch.</p>"},{"location":"development/#secrets-management","title":"Secrets management","text":"<p>Rules for secrets management: - Do not store secrets in the code, but use environment variables for this purpose when uploading the code somewhere. - When developing locally, store variables in the .env file to avoid accidentally uploading them to the network. - Never commit passwords, API keys, tokens, or other secrets directly to a repository (even a private one).</p> <p>Resolving issues   - Prioritization: Critical bugs and blockers first, then new features.  - Time estimation: If a task takes longer than planned, inform the team in advance.</p>"},{"location":"quality_assurance/","title":"Quality assurance","text":""},{"location":"quality_assurance/#automated-tests","title":"Automated tests","text":"<ul> <li>Tools used for testing: </li> <li><code>pytest</code> \u2014 the main framework for unit and integration tests in all parts of the project  </li> <li><code>pytest-asyncio</code> \u2014 for testing asynchronous code  </li> <li> <p><code>unittest</code> and <code>unittest.mock</code> \u2014 for integration tests and mocking the database in the backend  </p> </li> <li> <p>Tests that we implemented: </p> </li> <li>Unit tests: <ul> <li>In the database connector repository:</li> <li>Mock tests for user CRUD operations</li> <li>Mock tests for conversation CRUD operations</li> <li>Mock tests for log CRUD operations</li> <li>Tests for user models</li> <li>Tests for conversation models</li> <li>Tests for log models</li> <li>In the bot repository:</li> <li><code>test_start_new_user_unit</code>: Checks that the start function correctly handles a new user and prompts for a name.</li> <li><code>test_start_existing_user_unit</code>: Checks that the start function correctly handles an already registered user and ends the conversation.</li> <li><code>test_get_name_unit</code>: Verifies that the get_name function saves the user\u2019s name and ends the conversation.</li> <li><code>test_cancel_unit</code>: Ensures the cancel function sends a cancellation message and ends the conversation.</li> <li><code>test_help_command_unit</code>: Checks that the help_command function sends the help message.</li> </ul> </li> <li> <p>Integration tests: </p> <ul> <li>In the database connector repository:</li> <li>Tests for user API endpoints</li> <li>Tests for conversation API endpoints</li> <li>Tests for log API endpoints</li> <li>Tests for root and health endpoints</li> <li>In the bot repository:</li> <li><code>test_full_registration_and_ask_integration</code>: Simulates a full registration flow and ensures the name is saved.</li> <li><code>test_ask_and_ask_handler_integration</code>: Simulates asking a question and getting a response from the model.</li> <li><code>test_cancel_clears_conv_id_integration</code>: Ensures that cancelling a conversation removes the conversation ID from the user\u2019s context.</li> <li><code>test_start_network_error_integration</code>: Checks that the start function gracefully handles network errors.</li> <li><code>test_get_name_network_error_integration</code>: Checks that the get_name function gracefully handles network errors.</li> </ul> </li> <li> <p>Where tests of each type are in the repository: </p> </li> <li> <p>In the database connector repository:  </p> <ul> <li>All tests are located in the <code>tests/</code> directory:</li> <li>Unit tests:  <ul> <li><code>tests/test_cruds_mock.py</code> </li> <li><code>tests/test_models_user.py</code> </li> <li><code>tests/test_models_conv.py</code> </li> <li><code>tests/test_models_log.py</code></li> </ul> </li> <li>Integration tests:  <ul> <li><code>tests/test_api_integration.py</code></li> </ul> </li> <li>You can see the full test suite here.</li> </ul> </li> <li> <p>In the bot repository:  </p> <ul> <li>All tests are located in the <code>tests/test_all.py</code> file.  </li> <li>You can see the full test suite here.</li> </ul> </li> </ul>"},{"location":"quality_chars/","title":"Quality Attribute Scenarios","text":""},{"location":"quality_chars/#performance-efficiency","title":"Performance Efficiency","text":""},{"location":"quality_chars/#importance","title":"Importance","text":"<p>The support bot must quickly answer user questions, even during peak load hours. </p>"},{"location":"quality_chars/#1-concurrent-users-load","title":"1) Concurrent Users Load","text":"Attribute Performance Efficiency Source Multiple simultaneous users Stimulus 200 concurrent users ask questions at one time Artifact MARS Bot handling requests Environment Production environment during peak usage period Response The system processes all questions without significant delay and maintains responsiveness Response Measure Average response time for bot's answer is under 10 seconds, with no timeouts or failures <p>Test:  Perform load testing \u2014 simulate 200 simultaneous requests to the bot and measure the average response time and error rate.</p>"},{"location":"quality_chars/#2-performance-efficiency-time-behavior","title":"2) Performance Efficiency: Time-behavior","text":""},{"location":"quality_chars/#importance_1","title":"Importance","text":"<p>The user should receive a response almost instantly.</p> Attribute Performance Efficiency: Time-behavior Source User Stimulus User sends a question to the bot Artifact MARS Bot Environment Production Response Bot provides an answer to the user Response Measure 95% of responses are delivered within 5 seconds <p>Test:  Use logging to measure latency for each request, build a graph, and make sure that 95% fit within 5 seconds.</p>"},{"location":"quality_chars/#3-functional-suitability-functional-correctness","title":"3) Functional Suitability: Functional Correctness","text":""},{"location":"quality_chars/#importance_2","title":"Importance","text":"<p>The user should receive relevant and correct answers. Any incorrect or \"broken\" answer reduces the credibility of the system.</p> Attribute Functional Suitability: Functional Correctness Source User Stimulus User asks a supported question to the bot Artifact MARS Bot Environment Production Response Bot provides the correct and expected answer Response Measure At least 98% of test questions (from the reference set) are answered correctly <p>Test: Create a test set of question-answers and run these questions through the bot, calculate the percentage of correct answers.</p>"}]}